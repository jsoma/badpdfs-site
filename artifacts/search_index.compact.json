{"documents":[{"id":"m27","slug":"m27","title":"Extracting Data Tables from Oklahoma Booze Licensees PDF","description":"This PDF contains detailed tables listing alcohol licensees in Oklahoma. It has multi-line cells making it hard to extract data accurately. Challenges include alternative row colors instead of lines (\"zebra stripes\"), complicating row differentiation and extraction.","content":"Extracting Data Tables from Oklahoma Booze Licensees PDF\n\nThis PDF contains detailed tables listing alcohol licensees in Oklahoma. It has zebra-striped, multi-line cells without lines, making it hard to extract data accurately.\n\n...or is that helpful?\nfrom natural_pdf import PDF\n\npdf = PDF(\"m27.pdf\")\npage = pdf.pages[0]\npage.show()\nExclusions\n\nFirst let's think about what we don't want: headers and footers.\nheader = page.find(text=\"PREMISE\").above()\nfooter = page.find(\"text:regex(Page \\d+ of)\")\n...","code":"from natural_pdf import PDF\n\npdf = PDF(\"m27.pdf\")\npage = pdf.pages[0]\npage.show()\nheader = page.find(text=\"PREMISE\").above()\nfooter = page.find(\"text:regex(Page \\d+ of)\")\n(header + footer).show()\nprint(\"Before exclusions:\", page.extract_text()[:200])\n\n# Add exclusions\npdf.add_exclusion(lambda page: ...","methods":["Guides","PDF","above","add_exclusion","below","expand","extract_table","extract_text","find","find_all","right","show","to_df"],"selectors":["text","text:regex(Page \\d+ of)"],"tags":["data tables","multiline cells","PDF extraction issues","row colors"],"complexity":12,"pdf":"m27.pdf"},{"id":"24480polcompleted","slug":"24480polcompleted","title":"Animal 911 Calls Extraction from Rainforest Cafe Report","description":"This PDF is a service call report covering 911 incidents at the Rainforest Cafe in Niagara Falls, NY. We're hunting for animals! The data is formatted as a spreadsheet within the PDF, and challenges include varied column widths, borderless tables, and large swaths of missing data.","content":"Animal 911 Calls Extraction from Rainforest Cafe Report\n\nThis PDF is a service call report covering 911 incidents at the Rainforest Cafe in Niagara Falls, NY. We're hunting for animals! The data is formatted as a spreadsheet within the PDF, and challenges include varied column widths, borderless tables, and large swaths of missing data.\nfrom natural_pdf import PDF\n\npdf = PDF(\"24480polcompleted.pdf\")\npdf.show(cols=3, limit=9)\nSelecting a subset of pages\n\nWe only want the spreadsheet pages, which ...","code":"from natural_pdf import PDF\n\npdf = PDF(\"24480polcompleted.pdf\")\npdf.show(cols=3, limit=9)\npages = pdf.pages[4:]\npages.show(cols=6)\npages[-1].show(crop=200)\n(\n  pages[-1]\n  .find_all('text:regex(\\\\d+ Records Found)')\n  .show(crop=100)\n)\npages[-1].add_exclusion('text:regex(\\\\d+ Records Found)')\npdf.ad...","methods":["Guides","PDF","add_exclusion","extract_table","find_all","from_content","show","to_df"],"selectors":["text:regex(\\\\d+ Records Found)","text:starts-with(NF-)"],"tags":["Animal 911 Logs","PDF Spreadsheet","Truncated Columns","Selective Redactions"],"complexity":14,"pdf":"24480polcompleted.pdf"},{"id":"k046682-111320-opa-lea-database-install_1","slug":"k046682-111320-opa-lea-database-install_1","title":"Complex Extraction of Law Enforcement Complaints","description":"This PDF contains a set of complaint records from a local law enforcement agency. Challenges include its relational data structure, unusual formatting common in the region, and redactions that disrupt automatic parsing.","content":"Complex Extraction of Law Enforcement Complaints\n\nThis PDF contains a set of complaint records from a local law enforcement agency. Challenges include its relational data structure, unusual formatting common in the region, and redactions that disrupt automatic parsing.\nfrom natural_pdf import PDF\n\npdf = PDF(\"k046682-111320-opa-lea-database-install_1.pdf\")\npdf.show(cols=3)\nLet's look at a single page\npage = pdf.pages[0]\npage.show()\nAdding exclusions\n\nWe don't like the top and bottom areas, so we'...","code":"from natural_pdf import PDF\n\npdf = PDF(\"k046682-111320-opa-lea-database-install_1.pdf\")\npdf.show(cols=3)\npage = pdf.pages[0]\npage.show()\npdf.add_exclusion(lambda page: page.find(text='L.E.A. Data Technologies').below(include_source=True))\npdf.add_exclusion(lambda page: page.find(text='Complaints By ...","methods":["Guides","PDF","above","add_exclusion","below","expand","extract_table","extract_text","find","find_all","from_lines","get_sections","merge","right","show","to_df"],"selectors":["text","text:contains(Address)","text:contains(Complainant)","text:contains(Complaint #)","text:contains(Completed)","text:contains(DOB)","text:contains(Date Assigned)","text:contains(Gender)","text:contains(H Phone)","text:contains(Investigator)","text:contains(Number)","text:contains(Officer #)","text:contains(Recorded)"],"tags":["law enforcement","PDF extraction","redactions","relational data","complex formatting"],"complexity":20,"pdf":"k046682-111320-opa-lea-database-install_1.pdf"},{"id":"use-of-force-raw","slug":"use-of-force-raw","title":"Extracting Use-of-Force Records from Vancouver Police PDF","description":"This PDF contains detailed records of Vancouver Police's use-of-force incidents, provided after a public records request by journalists. Challenges include its very very very small font size and lots of empty whitespace.","content":"Extracting Use-of-Force Records from Vancouver Police PDF\n\nThis PDF contains detailed records of Vancouver Police's use-of-force incidents, provided after a public records request by journalists. Challenges include its very small font size and lots of empty whitespace.\nfrom natural_pdf import PDF\n\npdf = PDF(\"use-of-force-raw.pdf\")\npage = pdf.pages[0]\npage.show()\nLet's find all the headers, they're the text at the top of the pag, which means they have the smallest y0.\nheaders = page.find_all('tex...","code":"from natural_pdf import PDF\n\npdf = PDF(\"use-of-force-raw.pdf\")\npage = pdf.pages[0]\npage.show()\nheaders = page.find_all('text[y0=min()]')\nheaders.extract_each_text()\nfrom natural_pdf.analyzers.guides import Guides\n\nguides = Guides(page)\nguides.vertical.from_headers(headers)\nguides.show()\nguides.extra...","methods":["Guides","PDF","extract_each_text","extract_table","find_all","from_headers","show","to_df"],"selectors":["text[y0=min()]"],"tags":["small font","public records","tables","sparse"],"complexity":5,"pdf":"use-of-force-raw.pdf"},{"id":"sample-bop-policy-restaurant","slug":"sample-bop-policy-restaurant","title":"Extracting Business Insurance Details from BOP PDF","description":"This PDF is a complex insurance policy document generated for small businesses requiring BOP coverage. It contains an overwhelming amount of information across 111 pages. Challenges include varied forms that may differ slightly between carriers, making extraction inconsistent. It has to deal with different templated layouts, meaning even standard parts can shift when generated by different software.","content":"Extracting Business Insurance Details from BOP PDF\n\nThis PDF is a complex insurance policy document generated for small businesses requiring BOP coverage. It contains an overwhelming amount of information across 111 pages. Challenges include varied forms that may differ slightly between carriers, making extraction inconsistent. It has to deal with different templated layouts, meaning even standard parts can shift when generated by different software.\nfrom natural_pdf import PDF\nfrom natural_pdf....","code":"from natural_pdf import PDF\nfrom natural_pdf.analyzers.guides import Guides\n\npdf = PDF(\"sample-bop-policy-restaurant.pdf\")\npage = pdf.pages[0]\npage.show()\npage.find_all('text[color~=red]').show()\n# pdf.add_exclusion('text[color~=red]')\npdf.find_all('text[color~=red]').exclude()\n(\n    page\n    .find(...","methods":["Guides","PDF","add_exclusion","exclude","expand","extract_text","find","find_all","region","right","show"],"selectors":["text[color~=red]"],"tags":["Insurance Policy","Complex Layouts","Templated Documents","Watermark"],"complexity":12,"pdf":"sample-bop-policy-restaurant.pdf"},{"id":"liberty-county-boe","slug":"liberty-county-boe","title":"Bad OCR in a board of education annual financial report","description":"This PDF is all sorts of information about the Board of Education in Liberty County, Georgia","content":"Bad OCR in a board of education annual financial report\n\nSo we have a reasonably long PDF (72 pages) that we want to grab a single page of information from. On top of everything else the text recognition (OCR) is bad. We'll need to redo that, so we'll start by reading the PDF in with text_layer=False to have it discard the incorrect text.\nfrom natural_pdf import PDF\n\npdf = PDF(\"liberty-county-boe.pdf\", text_layer=False)\npdf.pages.show(cols=6)\nNow we need to apply new OCR to it.\n\nWe're impatient ...","code":"from natural_pdf import PDF\n\npdf = PDF(\"liberty-county-boe.pdf\", text_layer=False)\npdf.pages.show(cols=6)\npdf.pages[5:20].apply_ocr()\npdf.find(text=\"FINANCIAL HIGHLIGHTS\").show()\npage = pdf.find(text=\"FINANCIAL HIGHLIGHTS\").page\npage.show()\ntext = page.extract_text()\nprint(text)\n\nwith open(\"content....","methods":["PDF","extract_text","find","render","save","show"],"selectors":[],"tags":["financial report","multi-page","OCR","page navigation"],"complexity":6,"pdf":"liberty-county-boe.pdf"},{"id":"ocr-example","slug":"ocr-example","title":"OCR and AI magic","description":"Master OCR techniques with Natural PDF - from basic text recognition to advanced LLM-powered corrections. Learn to extract text from image-based PDFs, handle tables without proper boundaries, and leverage AI for accuracy improvements.","content":"OCR: Recognizing text\n\nSometimes you can't actually get the text off of the page. It's an image of text instead of being actual text.\nfrom natural_pdf import PDF\n\npdf = PDF(\"ocr-example.pdf\")\n\npage = pdf.pages[0]\npage.show(width=700)\nLooks like it's full of words, right? But when we try to extract the text, it doesn't go as planned.\ntext = page.extract_text()\nprint(text)\nNothing \u2013 it's time for OCR!\n\nOCR stands for Optical Character Recognition, which just means detecting characters from images....","code":"from natural_pdf import PDF\n\npdf = PDF(\"ocr-example.pdf\")\n\npage = pdf.pages[0]\npage.show(width=700)\ntext = page.extract_text()\nprint(text)\npage.apply_ocr()\ntext = page.extract_text()\nprint(text)\npage.apply_ocr('surya', resolution=192)\ntext = page.extract_text()\nprint(text)\npage.extract_table()\ntable...","methods":["Guides","PDF","apply_ocr","below","correct_ocr","extract_table","extract_text","find","find_all","from_content","from_lines","inspect","show","snap_to_whitespace","to_df"],"selectors":["text","text:contains(Violations)"],"tags":["OCR","LLM Integration","Text Extraction","Table Detection","AI Correction"],"complexity":28,"pdf":"ocr-example.pdf"},{"id":"mednine","slug":"mednine","title":"Arabic Election Results Table Extraction from Mednine PDF","description":"This PDF has a data table showing election results from the Tunisian region of Mednine. Challenges include spanning header cells and rotated headers. It has Arabic script.","content":"Arabic Election Results Table Extraction from Mednine PDF\n\nThis PDF has a data table showing election results from the Tunisian region of Mednine. Challenges include spanning header cells and rotated headers. It has Arabic script.\n\nUpdated for testing caching system with cascading dependencies!\nfrom natural_pdf import PDF\n\npdf = PDF(\"mednine.pdf\")\npdf.show(cols=3)\nI spent far too long making sure Natural PDF supports right-to-left scripts like Arabic. While I can't read them to confirm, I'm vagu...","code":"from natural_pdf import PDF\n\npdf = PDF(\"mednine.pdf\")\npdf.show(cols=3)\nfrom natural_pdf.flows import Flow\n\nflow = Flow(pdf.pages, arrangement='vertical')\nflow.show(width=300)\ndf = flow.extract_table().to_df(header=None)\ndf\nimport pandas as pd\ndataframes = pdf.pages.apply(\n    lambda page: page.extra...","methods":["Flow","PDF","apply","astype","extract_table","replace","show","to_df"],"selectors":[],"tags":["Election Results","Arabic Script","Table Extraction","Header Challenges"],"complexity":5,"pdf":"mednine.pdf"},{"id":"multicolumn","slug":"multicolumn","title":"Working with page structure","description":"Extract text from complex multi-column layouts while maintaining proper reading order. Learn techniques for handling academic papers, newsletters, and documents with intricate column structures using Natural PDF's layout detection features.","content":"Multi-page flows\n\nSometimes you have data that flows over multiple columns, or pages, or just... isn't arranged in a \"normal\" top-to-bottom way.\nfrom natural_pdf import PDF\n\npdf = PDF(\"multicolumn.pdf\")\npage = pdf.pages[0]\npage.show()\nNatural PDF deals with these through [reflowing pages](https://jsoma.github.io/natural-pdf/reflowing-pages/), where you grab specific regions of a page and then paste them back together either vertically or horizontally.\n\nIn this example we're splitting the page in...","code":"from natural_pdf import PDF\n\npdf = PDF(\"multicolumn.pdf\")\npage = pdf.pages[0]\npage.show()\nleft = page.region(left=0, right=page.width/3, top=0, bottom=page.height)\nmid = page.region(left=page.width/3, right=page.width/3*2, top=0, bottom=page.height)\nright = page.region(left=page.width/3*2, right=pag...","methods":["Flow","Guides","PDF","analyze_layout","apply_ocr","below","extract_table","extract_text","find","find_all","from_lines","highlight","region","show","to_df"],"selectors":["region","region[type=table-column]","region[type=table]","table","text:contains(\"Table one\")","text[source=ocr]","text[width>10]:bold"],"tags":["Multi-Column Layout","Reading Order","Text Flow","Academic Papers","Layout Detection","Table Extraction","YOLO","TATR"],"complexity":22,"pdf":"multicolumn.pdf"},{"id":"pomonajailpomonaca06212004","slug":"pomonajailpomonaca06212004","title":"ICE Detention Facilities Compliance Report Extraction","description":"This PDF is an ICE report on compliance among detention facilities over the last 20-30 years. Our aim is to extract facility statuses and contract signatories' names and dates. Challenges include strange redactions, blobby text, poor contrast, and ineffective OCR. It has handwritten signatures and dates that are redacted.","content":"ICE Detention Facilities Compliance Report Extraction\n\nThis PDF is an ICE report on compliance among detention facilities over the last 20-30 years. Our aim is to extract facility statuses and contract signatories' names and dates. Challenges include strange redactions, blobby text, poor contrast, and ineffective OCR. It has handwritten signatures and dates that are redacted.\n\nLet's take a look at one of the form pages. The text recognition isn't very good so wer'e going to load it in with text_...","code":"from natural_pdf import PDF\n\npdf = PDF(\"pomonajailpomonaca06212004.pdf\", text_layer=False)\npage = pdf.pages[3]\npage.show()\n# pdf.apply_ocr(resolution=192) if we wanted the whole thing\npage.apply_ocr(resolution=192)\ntext = page.extract_text()[:200]\nprint(text)\nleft_col = page.region(right=page.width/...","methods":["Judge","PDF","add","apply_ocr","below","expand","extract_text","find","forget","left","region","show","trim"],"selectors":["text:closest(County)","text:closest(Dates of Review)","text:closest(Previous Rating)","text:contains(Name and Location)","text[text=Class Action Order]","text[text=Court Order]","text[text=Major Litigation]","text[text=No]"],"tags":["ICE compliance report","Redacted text","Handwriting","OCR needed","Text extraction issues","Columns"],"complexity":15,"pdf":"pomonajailpomonaca06212004.pdf"},{"id":"basics","slug":"basics","title":"Natural PDF basics with text and tables","description":"Learn the fundamentals of Natural PDF - opening PDFs, extracting text with layout preservation, selecting elements by criteria, spatial navigation, and managing exclusion zones. Perfect starting point for PDF data extraction.","content":"Opening a PDF\n\nLet's start by opening a PDF. Natural PDF can work with local files or URLs.\nfrom natural_pdf import PDF\n\npdf = PDF(\"basics.pdf\")\npage = pdf.pages[0]\npage.show()\nGrabbing Page Text\n\nYou can extract text while preserving the layout, which maintains the spatial arrangement of text on the page.\ntext = page.extract_text(layout=True)\nprint(text)\nSelecting Elements and Text\n\nNatural PDF provides powerful selectors to find specific elements on the page.\n\nSelect text in a rectangle\npage.f...","code":"from natural_pdf import PDF\n\npdf = PDF(\"basics.pdf\")\npage = pdf.pages[0]\npage.show()\ntext = page.extract_text(layout=True)\nprint(text)\npage.find('rect').show()\ntext = page.find('rect').extract_text()\nprint(text)\npage.find_all('text').show()\ntexts = page.find_all('text').extract_each_text()\nfor t in ...","methods":["PDF","add_exclusion","extract_each_text","extract_table","extract_text","find","find_all","region","right","show","to_df"],"selectors":["line","rect","text","text:contains(\"INS-\")","text[color~=red]"],"tags":["Text Extraction","Basic Usage","Element Selection","Spatial Navigation","Tables","Exclusion Zones"],"complexity":14,"pdf":"basics.pdf"},{"id":"serbia-zakon-o-naknadama-za-koriscenje-javnih","slug":"serbia-zakon-o-naknadama-za-koriscenje-javnih","title":"Extracting Complex Data from Serbian Regulatory PDF","description":"This PDF contains parts of Serbian policy documents, crucial for a research project analyzing industry policies across countries. The challenge lies in extracting a large table that spans pages (page 90 to 97) and a math formula on page 98, all in Serbian. Both elements lack clear boundaries between pages, complicating extraction.","content":"Extracting Complex Data from Serbian Regulatory PDF\n\nThis PDF contains parts of Serbian policy documents, crucial for a research project analyzing industry policies across countries. The challenge lies in extracting a large table that spans pages (page 90 to 97) and a math formula on page 98, all in Serbian. Both elements lack clear boundaries between pages, complicating extraction.\nfrom natural_pdf import PDF\nfrom natural_pdf.analyzers.guides import Guides\n\npdf = PDF(\"serbia-zakon-o-naknadama-z...","code":"from natural_pdf import PDF\nfrom natural_pdf.analyzers.guides import Guides\n\npdf = PDF(\"serbia-zakon-o-naknadama-za-koriscenje-javnih.pdf\")\npdf.pages[:8].show(cols=4)\nfirst_page = pdf.find(text=\"Prilog 7.\").page\nlast_page = pdf.find(text='VISINA NAKNADE ZA ZAGA\u0110ENJE VODA').page\npages = pdf.pages[fir...","methods":["Guides","PDF","below","extract_table","find","show","to_df"],"selectors":["image"],"tags":["Serbian","Large Tables","Math Formulas","Regulatory Documents","multiple tables","spanning pages"],"complexity":9,"pdf":"serbia-zakon-o-naknadama-za-koriscenje-javnih.pdf"},{"id":"20252026-236232","slug":"20252026-236232","title":"Extracting Text from Georgia Legislative Bills","description":"This PDF contains legal bills from the Georgia legislature, published yearly. Challenges include extracting marked-up text like underlines and strikethroughs. It has line numbers that complicate text extraction. ","content":"Extracting Text from Georgia Legislative Bills\n\nThis PDF contains legal bills from the Georgia legislature, published yearly. Challenges include extracting marked-up text like underlines and strikethroughs. It has line numbers that complicate text extraction... or do they make it easier?\nfrom natural_pdf import PDF\n\npdf = PDF(\"20252026-236232.pdf\")\npage = pdf.pages[-1]\npage.show()\nText with strikethroughs\n\nSee those strikeouts? Usually they're awful, terrible, impossible. When you use .extract_t...","code":"from natural_pdf import PDF\n\npdf = PDF(\"20252026-236232.pdf\")\npage = pdf.pages[-1]\npage.show()\ntext = page.extract_text()\nprint(text)\npage.find_all('text:strikeout').show(crop='wide')\nunderlined = page.find_all('text:underline')\nprint(\"Underlined text is\", underlined.extract_text())\nunderlined.show(...","methods":["PDF","add_exclusion","apply","extract_each_text","extract_text","find_all","merge","region","right","show"],"selectors":["text","text:strikeout","text:underline"],"tags":["text extraction","legislative documents","PDF challenges","text formatting"],"complexity":21,"pdf":"20252026-236232.pdf"},{"id":"cia-document","slug":"cia-document-extraction","title":"CIA Document Analysis","description":"Extracting information from declassified CIA documents using AI","content":"CIA Document Classification\n\nLet's work with a declassified CIA document and use AI to classify and extract information.\nfrom natural_pdf import PDF\n\npdf = PDF(\"cia-doc.pdf\")\npdf.pages.show(cols=6)\nJust like we did above, we can ask what category we think the PDF belongs to.\npdf.classify(\n    ['slaughterhouse report', 'dolphin training manual', 'basketball', 'birding'],\n    using='text'\n)\n(pdf.category, pdf.category_confidence)\nI promise birding is real! The PDF is about using pigeons to take su...","code":"from natural_pdf import PDF\n\npdf = PDF(\"cia-doc.pdf\")\npdf.pages.show(cols=6)\npdf.classify(\n    ['slaughterhouse report', 'dolphin training manual', 'basketball', 'birding'],\n    using='text'\n)\n(pdf.category, pdf.category_confidence)\npdf.classify_pages(\n    ['diagram', 'text', 'invoice', 'blank'],\n  ...","methods":["PDF","classify","classify_pages","filter","groupby","info","save_pdf","show"],"selectors":[],"tags":["workshop","ai","government-documents"],"complexity":7,"pdf":"cia-doc.pdf"},{"id":"statecallcenterdata_redacted","slug":"statecallcenterdata_redacted","title":"Extracting State Agency Call Center Wait Times from FOIA PDF","description":"This PDF contains data on wait times at a state agency call center. The main focus is on the data on the first two pages, which matches other states' submission formats. The later pages provide granular breakdowns over several years. Challenges include it being heavily pixelated, making it hard to read numbers and text, with inconsistent and unreadable charts.","content":"Extracting State Agency Call Center Wait Times from FOIA PDF\n\nThis PDF contains data on wait times at a state agency call center. The main focus is on the data on the first two pages, which matches other states' submission formats. The later pages provide granular breakdowns over several years. Challenges include it being heavily pixelated, making it hard to read numbers and text, with inconsistent and unreadable charts.\n\nThe submission said \"the first two pages\" so I'm going with that. The rest...","code":"from natural_pdf import PDF\n\npdf = PDF(\"statecallcenterdata_redacted.pdf\")\npage = pdf.pages[0]\npage.show()\n# No results? Needs OCR!\nprint(page.extract_text())\npage.apply_ocr('surya')\npage.find_all('text').show(crop=True)\nprint(page.extract_text(layout=True))\ntable_area = (\n    page\n    .find('text:c...","methods":["Guides","PDF","apply_ocr","below","divide","expand","extract_table","extract_text","find","find_all","from_lines","show","snap_to_whitespace","to_df"],"selectors":["text","text:contains(Figure)"],"tags":["Call Center Data","Pixelated Scan","OCR Required","Granular Breakdown"],"complexity":10,"pdf":"statecallcenterdata_redacted.pdf"},{"id":"czech-republic-pisa2012_zakovsky_dotaznik_a","slug":"czech-republic-pisa2012_zakovsky_dotaznik_a","title":"Complex Table Extraction from OECD Czech PISA Assessment","description":"This PDF is a document from the OECD regarding the PISA assessment, provided in Czech. The main extraction goal is to get the survey question table found on page 9. Challenges include the weird table format, making it hard to extract automatically.","content":"Complex Table Extraction from OECD Czech PISA Assessment\n\nThis PDF is a document from the OECD regarding the PISA assessment, provided in Czech. The main extraction goal is to get the survey question table found on page 9. Challenges include the weird table format, making it hard to extract automatically.\n\nI'm assuming by \"survey question\" the submitter wants as much as possible. You can extend the work we do here to get all of the surveys in the PDF, but for now we're just going to do a single ...","code":"from natural_pdf import PDF\n\npdf = PDF(\"czech-republic-pisa2012_zakovsky_dotaznik_a.pdf\")\npdf.pages[6:15].show()\npdf.pages[7].find_all(\"text:bold:not-empty\").show()\npdf.pages[7].inspect()\npdf.pages[7].find_all(\"text:bold:not-empty\").dissolve().show()\nquestions = (\n    pdf\n    .pages[6:15]\n    .find_...","methods":["PDF","dissolve","extract_text","find_all","inspect","show"],"selectors":["text","text:bold","text:bold:not-empty","text:bold[size~=14][x0>100]:not-empty","text:italic:not-empty[size>8]","text:italic[size~=14]","text:not(:bold):not(:italic)[size=12]","text:not(:italic):not-empty[size>8]"],"tags":["OECD","Czech","PISA","Survey Table","Complex Format"],"complexity":19,"pdf":"czech-republic-pisa2012_zakovsky_dotaznik_a.pdf"},{"id":"focus","slug":"focus","title":"Extracting Economic Data from Brazil's Central Bank PDF","description":"This PDF is the weekly \u201cFocus\u201d report from Brazil\u2019s central bank with economic projections and statistics. Challenges include commas instead of decimal points, images showing projection changes, and tables without border lines that merge during extraction.","content":"Extracting Economic Data from Brazil's Central Bank PDF\n\nThis PDF is the weekly \u201cFocus\u201d report from Brazil\u2019s central bank with economic projections and statistics. Challenges include commas instead of decimal points, images showing projection changes, and tables without border lines that merge during extraction.\nfrom natural_pdf import PDF\n\npdf = PDF(\"focus.pdf\")\npage = pdf.pages[0]\npage.show()\nLet's cut out the part of the page we're interested in: everything from Expectativas to the long, ligh...","code":"from natural_pdf import PDF\n\npdf = PDF(\"focus.pdf\")\npage = pdf.pages[0]\npage.show()\ndata = (\n    page\n    .find(text='Expectativas')\n    .below(\n        until='text:contains(comportamento)',\n        include_endpoint=False\n    )\n)\n    \ndata.show(crop=True)\nrow_names = (\n    data\n    .find(text='IPCA'...","methods":["PDF","assign","below","clip","dropna","expand","extract_table","extract_text","find","find_all","right","show","to_df"],"selectors":["text","text:contains(2025)","text:contains(2026)","text:contains(2027)","text:contains(2028)","text[size~=10]:regex(\\d\\d\\d\\d)"],"tags":["Brazil","Economic Data","PDF Extraction","Tables without Borders","Comma as Decimal","Image Interpretation"],"complexity":18,"pdf":"focus.pdf"}],"methodIndex":{"Flow":["mednine","multicolumn"],"Guides":["24480polcompleted","k046682-111320-opa-lea-database-install_1","m27","multicolumn","ocr-example","sample-bop-policy-restaurant","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted","use-of-force-raw"],"Judge":["pomonajailpomonaca06212004"],"PDF":["20252026-236232","24480polcompleted","basics","cia-document","czech-republic-pisa2012_zakovsky_dotaznik_a","focus","k046682-111320-opa-lea-database-install_1","liberty-county-boe","m27","mednine","multicolumn","ocr-example","pomonajailpomonaca06212004","sample-bop-policy-restaurant","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted","use-of-force-raw"],"above":["k046682-111320-opa-lea-database-install_1","m27"],"add":["pomonajailpomonaca06212004"],"add_exclusion":["20252026-236232","24480polcompleted","basics","k046682-111320-opa-lea-database-install_1","m27","sample-bop-policy-restaurant"],"analyze_layout":["multicolumn"],"apply":["20252026-236232","mednine"],"apply_ocr":["multicolumn","ocr-example","pomonajailpomonaca06212004","statecallcenterdata_redacted"],"assign":["focus"],"astype":["mednine"],"below":["focus","k046682-111320-opa-lea-database-install_1","m27","multicolumn","ocr-example","pomonajailpomonaca06212004","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted"],"classify":["cia-document"],"classify_pages":["cia-document"],"clip":["focus"],"correct_ocr":["ocr-example"],"dissolve":["czech-republic-pisa2012_zakovsky_dotaznik_a"],"divide":["statecallcenterdata_redacted"],"dropna":["focus"],"exclude":["sample-bop-policy-restaurant"],"expand":["focus","k046682-111320-opa-lea-database-install_1","m27","pomonajailpomonaca06212004","sample-bop-policy-restaurant","statecallcenterdata_redacted"],"extract_each_text":["20252026-236232","basics","use-of-force-raw"],"extract_table":["24480polcompleted","basics","focus","k046682-111320-opa-lea-database-install_1","m27","mednine","multicolumn","ocr-example","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted","use-of-force-raw"],"extract_text":["20252026-236232","basics","czech-republic-pisa2012_zakovsky_dotaznik_a","focus","k046682-111320-opa-lea-database-install_1","liberty-county-boe","m27","multicolumn","ocr-example","pomonajailpomonaca06212004","sample-bop-policy-restaurant","statecallcenterdata_redacted"],"filter":["cia-document"],"find":["basics","focus","k046682-111320-opa-lea-database-install_1","liberty-county-boe","m27","multicolumn","ocr-example","pomonajailpomonaca06212004","sample-bop-policy-restaurant","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted"],"find_all":["20252026-236232","24480polcompleted","basics","czech-republic-pisa2012_zakovsky_dotaznik_a","focus","k046682-111320-opa-lea-database-install_1","m27","multicolumn","ocr-example","sample-bop-policy-restaurant","statecallcenterdata_redacted","use-of-force-raw"],"forget":["pomonajailpomonaca06212004"],"from_content":["24480polcompleted","ocr-example"],"from_headers":["use-of-force-raw"],"from_lines":["k046682-111320-opa-lea-database-install_1","multicolumn","ocr-example","statecallcenterdata_redacted"],"get_sections":["k046682-111320-opa-lea-database-install_1"],"groupby":["cia-document"],"highlight":["multicolumn"],"info":["cia-document"],"inspect":["czech-republic-pisa2012_zakovsky_dotaznik_a","ocr-example"],"left":["pomonajailpomonaca06212004"],"merge":["20252026-236232","k046682-111320-opa-lea-database-install_1"],"region":["20252026-236232","basics","multicolumn","pomonajailpomonaca06212004","sample-bop-policy-restaurant"],"render":["liberty-county-boe"],"replace":["mednine"],"right":["20252026-236232","basics","focus","k046682-111320-opa-lea-database-install_1","m27","sample-bop-policy-restaurant"],"save":["liberty-county-boe"],"save_pdf":["cia-document"],"show":["20252026-236232","24480polcompleted","basics","cia-document","czech-republic-pisa2012_zakovsky_dotaznik_a","focus","k046682-111320-opa-lea-database-install_1","liberty-county-boe","m27","mednine","multicolumn","ocr-example","pomonajailpomonaca06212004","sample-bop-policy-restaurant","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted","use-of-force-raw"],"snap_to_whitespace":["ocr-example","statecallcenterdata_redacted"],"to_df":["24480polcompleted","basics","focus","k046682-111320-opa-lea-database-install_1","m27","mednine","multicolumn","ocr-example","serbia-zakon-o-naknadama-za-koriscenje-javnih","statecallcenterdata_redacted","use-of-force-raw"],"trim":["pomonajailpomonaca06212004"]},"suggestions":{"methods":["Flow","Guides","Judge","PDF","above","add","add_exclusion","analyze_layout","apply","apply_ocr","assign","astype","below","classify","classify_pages","clip","correct_ocr","dissolve","divide","dropna","exclude","expand","extract_each_text","extract_table","extract_text","filter","find","find_all","forget","from_content","from_headers","from_lines","get_sections","groupby","highlight","info","inspect","left","merge","region","render","replace","right","save","save_pdf","show","snap_to_whitespace","to_df","trim"],"terms":["about","academic","accuracy","accurately","across","advanced","after","agency","alcohol","alternative","among","amount","analysis","analyzing","animal","animals","annual","arabic","assessment","automatic","automatically","bank","based","basic","basics","being","between","bills","blobby","board","booze","border","borderless","both","boundaries","brazil","breakdowns","business","businesses","cafe","call","calls","carriers","cells","center","central","challenge","challenges","changes","charts"]},"stats":{"totalDocuments":17,"totalMethods":49,"indexVersion":"2.0"}}
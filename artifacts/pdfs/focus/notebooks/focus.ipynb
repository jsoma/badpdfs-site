{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting Economic Data from Brazil's Central Bank PDF\n",
        "\n",
        "This PDF is the weekly \u201cFocus\u201d report from Brazil\u2019s central bank with economic projections and statistics. Challenges include commas instead of decimal points, images showing projection changes, and tables without border lines that merge during extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install natural-pdf\n",
        "!pip install natural-pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the PDF file\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "pdf_url = \"https://pub-4e99d31d19cb404d8d4f5f7efa51ef6e.r2.dev/pdfs/focus/focus.pdf\"\n",
        "pdf_name = \"focus.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_name):\n",
        "    print(f\"Downloading {pdf_name}...\")\n",
        "    urllib.request.urlretrieve(pdf_url, pdf_name)\n",
        "    print(f\"Downloaded {pdf_name}\")\n",
        "else:\n",
        "    print(f\"{pdf_name} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting Economic Data from Brazil's Central Bank PDF\n",
        "\n",
        "This PDF is the weekly \u201cFocus\u201d report from Brazil\u2019s central bank with economic projections and statistics. Challenges include commas instead of decimal points, images showing projection changes, and tables without border lines that merge during extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf import PDF\n",
        "\n",
        "pdf = PDF(\"focus.pdf\")\n",
        "page = pdf.pages[0]\n",
        "page.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's cut out the part of the page we're interested in: everything from **Expectativas** to the long, light text that starts with **comportamento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = (\n",
        "    page\n",
        "    .find(text='Expectativas')\n",
        "    .below(\n",
        "        until='text:contains(comportamento)',\n",
        "        include_endpoint=False\n",
        "    )\n",
        ")\n",
        "    \n",
        "data.show(crop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grabbing headers\n",
        "\n",
        "While we could type out the column names on the left, it's probably easier to just scrape them from the page. We start from IPCA, move down, clip it to the section we cut out earlier (otherwise it runs down the whole page), then find all of the text that even somewhat overlaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "row_names = (\n",
        "    data\n",
        "    .find(text='IPCA')\n",
        "    .below(width='element', include_source=True)\n",
        "    .clip(data)\n",
        "    .find_all('text', overlap='partial')\n",
        ")\n",
        "headers = row_names.extract_each_text()\n",
        "headers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "/// tab | Using sections\n",
        "## Horizontal sections\n",
        "\n",
        "While you usually use `.get_sections` to split pages vertically, you can also do it horizontally. In this case we'll find the year headers - four numbers in a row, size 10 font - and use them as our breakpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sections = (\n",
        "    data.get_sections(\n",
        "        start_elements=\"text[size~=10]:regex(\\d\\d\\d\\d)\",\n",
        "        include_boundaries='start',\n",
        "        orientation='horizontal'\n",
        "    )\n",
        ")\n",
        "sections.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll take the first table as an example. We don't want all of that junk up top \u2013 it's easy to retype multi-row headers \u2013 so we'll dial it back in a bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    sections[0]\n",
        "    .expand(top=-50)\n",
        "    .show()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we'll ask it to extract the content using the **stream** method, which uses the space between text. Even though we can see lines and backgrounds and all sorts of things, stream works consistently when other approaches don't!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    sections[0]\n",
        "    .expand(top=-50, right=0)\n",
        "    .extract_table('stream')\n",
        "    .to_df(header=False)\n",
        "    .dropna(axis=0, how='all')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We include the `.dropna` in there because stream injects some phantom rows full of empty values.\n",
        "\n",
        "## Looping through sections\n",
        "\n",
        "Now that we know how it works from one section, let's do it for all of them. We'll use `.apply` so that it creates a list of dataframes that we can combine later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframes = sections.apply(lambda section: (\n",
        "    section\n",
        "        .expand(top=-50, right=0)\n",
        "        .extract_table('stream')\n",
        "        .to_df(header=False)\n",
        "        .dropna(axis=0, how='all')\n",
        "        .assign(\n",
        "            year=section.find('text[size~=10]:regex(\\d\\d\\d\\d)').extract_text(),\n",
        "            value=headers\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.concat(dataframes, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.concat(dataframes, ignore_index=True)\n",
        "///\n",
        "\n",
        "/// tab | Manually selecting tables\n",
        "\n",
        "## Grabbing tables\n",
        "\n",
        "We start by grabbing the space between the 2025 and 2026 headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    data\n",
        "    .find('text:contains(2025)')\n",
        "    .right(\n",
        "        until='text:contains(2026)',\n",
        "        include_source=True,\n",
        "        include_endpoint=False\n",
        "    )\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...then we move down..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    data\n",
        "    .find('text:contains(2025)')\n",
        "    .right(\n",
        "        until='text:contains(2026)',\n",
        "        include_source=True,\n",
        "        include_endpoint=False\n",
        "    )\n",
        "    .below(width='element')\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...then we nudge the top down a little bit and clip it to the size of the region of interest (the `data` region)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = (\n",
        "    data\n",
        "    .find('text:contains(2025)')\n",
        "    .right(\n",
        "        until='text:contains(2026)',\n",
        "        include_source=True,\n",
        "        include_endpoint=False\n",
        "    )\n",
        "    .below(width='element')\n",
        "    .expand(top=-20)\n",
        "    .clip(data)\n",
        ")\n",
        "\n",
        "table.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could try to figure out something magic with all of the headers and colors and backgrounds and blah blah blah, but it's easier to just extract the table using the \"stream\" method, which looks at the gaps between rows and columns. While there *are* actual boundaries between the rows, I promise stream works the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2025 = table.expand(top=-5).extract_table('stream').to_df(header=False)\n",
        "df_2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It needs a *little* cleanup. Due to using the steam approach we got some extra (empty) columns, but we can just drop them with pandas. We'll also insert the year and the row titles that we grabbed up above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2025 = df_2025.dropna(axis=0, how='all')\n",
        "df_2025.insert(0, 'year', 2025)\n",
        "df_2025.insert(0, 'value', headers)\n",
        "df_2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working on all the other tables\n",
        "\n",
        "2026 is basically the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = (\n",
        "    data\n",
        "    .find('text:contains(2026)')\n",
        "    .right(\n",
        "        until='text:contains(2027)',\n",
        "        include_source=True,\n",
        "        include_endpoint=False\n",
        "    )\n",
        "    .below(width='element')\n",
        "    .expand(top=-20)\n",
        "    .clip(data)\n",
        ")\n",
        "table.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2026 = table.expand(top=-5).extract_table('stream').to_df(header=False).dropna(axis=0, how='all')\n",
        "df_2026.insert(0, 'year', 2026)\n",
        "df_2026.insert(0, 'value', headers)\n",
        "df_2026"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As is 2027."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = (\n",
        "    data\n",
        "    .find('text:contains(2027)')\n",
        "    .right(\n",
        "        until='text:contains(2028)',\n",
        "        include_source=True,\n",
        "        include_endpoint=False\n",
        "    )\n",
        "    .below(width='element')\n",
        "    .expand(top=-20)\n",
        "    .clip(data)\n",
        ")\n",
        "df_2027 = table.expand(top=-5).extract_table('stream').to_df(header=False).dropna(axis=0, how='all')\n",
        "df_2027.insert(0, 'year', 2027)\n",
        "df_2027.insert(0, 'value', headers)\n",
        "df_2027"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2028 is a *little* different because it doesn't including an endpoint on the right. We just blast on through until we hit the right-hand side of the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = (\n",
        "    data\n",
        "    .find('text:contains(2028)')\n",
        "    .right(include_source=True)\n",
        "    .below(width='element')\n",
        "    .expand(top=-20)\n",
        "    .clip(data)\n",
        ")\n",
        "df_2028 = table.expand(top=-5).extract_table('stream').to_df(header=False).dropna(axis=0, how='all')\n",
        "df_2028.insert(0, 'year', 2028)\n",
        "df_2028.insert(0, 'value', headers)\n",
        "df_2028"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll set up the dataframes in a nice long list to combine in the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframes = [df_2025, df_2026, df_2027, df_2028]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "///\n",
        "\n",
        "## Combining our data\n",
        "\n",
        "Now that we have a list of dataframes (no matter which path we took) we can just use pandas to concatenate them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.concat(dataframes, ignore_index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There we go!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
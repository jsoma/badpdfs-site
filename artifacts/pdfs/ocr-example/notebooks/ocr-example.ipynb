{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OCR and AI magic\n",
        "\n",
        "Master OCR techniques with Natural PDF - from basic text recognition to advanced LLM-powered corrections. Learn to extract text from image-based PDFs, handle tables without proper boundaries, and leverage AI for accuracy improvements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install natural-pdf\n",
        "!pip install natural-pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the PDF file\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "pdf_url = \"https://pub-4e99d31d19cb404d8d4f5f7efa51ef6e.r2.dev/pdfs/ocr-example/ocr-example.pdf\"\n",
        "pdf_name = \"ocr-example.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_name):\n",
        "    print(f\"Downloading {pdf_name}...\")\n",
        "    urllib.request.urlretrieve(pdf_url, pdf_name)\n",
        "    print(f\"Downloaded {pdf_name}\")\n",
        "else:\n",
        "    print(f\"{pdf_name} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OCR: Recognizing text\n",
        "\n",
        "Sometimes you can't actually get the text off of the page. It's an *image* of text instead of being actual text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf import PDF\n",
        "\n",
        "pdf = PDF(\"ocr-example.pdf\")\n",
        "\n",
        "page = pdf.pages[0]\n",
        "page.show(width=700)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like it's full of words, right? But when we try to extract the text, it doesn't go as planned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = page.extract_text()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nothing \u2013 **it's time for OCR!**\n",
        "\n",
        "OCR stands for Optical Character Recognition, which just means *detecting characters from images*. No one ever actually says \"optical character recognition,\" though, they always just call it \"OCR.\"\n",
        "\n",
        "There are a looooot of OCR engines out there, and one of the things that makes Natural PDF nice is that it supports multiples. Figuring out which one is the \"best\" isn't as tough when you can just run them all right after each other.\n",
        "\n",
        "The default is [EasyOCR](https://github.com/JaidedAI/EasyOCR) which usually works fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.apply_ocr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = page.extract_text()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I'm very iritated by the \"Durham's Pure Leaf Lardl\" instead of \"Durham's Pure Leaf Lard!\". Why'd it miss that??\n",
        "\n",
        "I don't need to know why, though, really, because I can just try some other engine! You can also fool around with the options - some of the the lowest-hanging fruit is increasing the resolution of the OCR. The default at the moment is 150, you can try upping to 300 for (potentially) better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.apply_ocr('surya', resolution=192)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = page.extract_text()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding tables on OCR documents\n",
        "\n",
        "When we used `page.extract_table()` last time, it was easy because there were all of these `line` elements on the page that pdfplumber could detect and say \"hey, it's a table!\" For the same reason that there's no *real* text on the page, there's also no *real* lines on the page. Instead, we're going to do a fun secret trick where we look at what horizontal and vertical coordinates *seem* like they might be lines by setting a threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.extract_table()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_area = (\n",
        "    page\n",
        "    .find('text:contains(Violations)')\n",
        "    .below(\n",
        "        until='text:contains(Jungle)',\n",
        "        include_endpoint=False\n",
        "    )\n",
        ")\n",
        "table_area.show(crop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf.analyzers import Guides\n",
        "\n",
        "guides = Guides(table_area)\n",
        "\n",
        "# Add guides between the headers\n",
        "guides.vertical.from_content(\n",
        "    ['Statute', 'Description', 'Level', 'Repeat'],\n",
        "    align='between'\n",
        ")\n",
        "\n",
        "# Shift them around so they don't overlap the text\n",
        "guides.vertical.snap_to_whitespace(detection_method='text')\n",
        "\n",
        "# add in horizontal lines in places where 80% of the pixels are 'used'\n",
        "guides.horizontal.from_lines(threshold=0.8)\n",
        "\n",
        "# Honestly you could have done the same thing for the vertical lines\n",
        "# but it isn't as fun as .from_content, you know?\n",
        "# n=5 finds the 5 most likely places based on pixel density\n",
        "# guides.vertical.from_lines(n=5)\n",
        "\n",
        "guides.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can just extract the data with `.extract_table()`..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = guides.extract_table().to_df()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But if you want to actually do things with specific columns or have more control, you can ask the guides for specific columns or rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "guides.columns[-1].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "guides.rows[3].show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figuring out information about things that are *not* text\n",
        "\n",
        "In a tiny preview of the next notebook: **what about those checkboxes?** Turns out we can use **image classification AI** to do it for us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_col = guides.columns[-1].expand(top=-40)\n",
        "last_col.show(crop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cells = guides.cells[-1][:]\n",
        "cells = cells.expand(left=-60, right=-175, top=-16, bottom=-16)\n",
        "cells.show(crop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cells.classify_all(['X', 'empty'], using='vision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cells.apply(lambda cell: (cell.category, cell.category_confidence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's like magic! We'll look at it more in another notebook.\n",
        "\n",
        "## Correcting OCR\n",
        "\n",
        "While we love OCR when it works, it often does *not* work great. We have a few solutions: send humans after it, or use LLMs or spell check to correct it.\n",
        "\n",
        "### With LLMs\n",
        "\n",
        "Let's OCR at a low resolution, then see what our text looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.apply_ocr(resolution=50)\n",
        "page.find_all('text').inspect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some of these are pretty easy - for example, \"Uraanilary Warking Conditions\" should be \"Unsanity working conditions.\" OCR tools just don't know that kind of thing! But what if we could go through each piece of text, some some sort of spell check or something?\n",
        "\n",
        "You can use `correct_ocr` to change the text in a region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correct_text_region(region):\n",
        "    return \"This is the updated text\"\n",
        "    \n",
        "page.correct_ocr(correct_text_region) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then, magically, all of our text is whatever we `return`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.find_all('text').inspect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But clearly we don't want the same thing every time! Let's add the bad OCR back in..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-apply the OCR to break it again\n",
        "page.apply_ocr('surya', resolution=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...and feed each line to an LLM trying to fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from natural_pdf.ocr.utils import direct_ocr_llm\n",
        "\n",
        "# Set your API key as an environment variable:\n",
        "# export OPENAI_API_KEY=\"your_actual_api_key\"\n",
        "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "\n",
        "prompt = \"\"\"\n",
        "Correct the spelling of this OCR'd text, a snippet of a document.\n",
        "Preserve original capitalization, punctuation, and symbols. \n",
        "Changing meaning is okay if it's clearly an OCR issue.\n",
        "Do not add any explanatory text, translations, comments, or quotation marks around the result.\n",
        "\"\"\"\n",
        "\n",
        "def correct_text_region(region):\n",
        "    text = region.extract_text()\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-nano\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\", \"content\": prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": text\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    updated = completion.choices[0].message.content\n",
        "\n",
        "    if text != updated:    \n",
        "        print(f\"OLD: {text}\\nNEW:{updated}\") \n",
        "\n",
        "    return updated\n",
        "\n",
        "page.correct_ocr(correct_text_region) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now we can use `.extract_text()` the magical same way.\n",
        "\n",
        "The real benefit of this vs sending the whole document to the LLM is *we don't change where the text is*. An LLM might OCR something for us, but it *loses the spatial context that we find so important*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = page.extract_text()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's do the OCR with the LLM, period\n",
        "\n",
        "But if the LLM is *that good* at OCR, we can also find pieces of the page we would like to OCR and *send them each in isolation to the LLM*. We use `detect_only=True` so it doesn't try to figure out what the text is, just that the text is there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.apply_ocr('surya', detect_only=True)\n",
        "page.find_all('text').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.find_all('text').inspect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll do an even fancier `correct_text_region`: it takes the region as an image, and sends it right on over to the LLM for OCR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from natural_pdf.ocr.utils import direct_ocr_llm\n",
        "\n",
        "# Set your API key as an environment variable:\n",
        "# export OPENAI_API_KEY=\"your_actual_api_key\"\n",
        "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
        "\n",
        "prompt = \"\"\"OCR this image patch. Return only the exact text content visible in the image. \n",
        "Preserve original spelling, capitalization, punctuation, and symbols.\n",
        "Fix misspellings if they are the result of blurry or incorrect OCR.\n",
        "Do not add any explanatory text, translations, comments, or quotation marks around the result.\n",
        "If you cannot process the image or do not see any text, return an empty space.\n",
        "The text is from an inspection report of a slaughterhouse.\"\"\"\n",
        "# The text is likely from a Greek document, potentially a spreadsheet, containing Modern Greek words or numbers\n",
        "\n",
        "def correct_text_region(region):\n",
        "    # Use a high resolution for the LLM call for best accuracy\n",
        "    return direct_ocr_llm(\n",
        "        region, \n",
        "        client, \n",
        "        prompt=prompt, \n",
        "        resolution=150, \n",
        "        model=\"gpt-4o\" \n",
        "    )\n",
        "\n",
        "page.correct_ocr(correct_text_region) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What do we have now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.find_all('text').inspect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = page.extract_text()\n",
        "print(text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
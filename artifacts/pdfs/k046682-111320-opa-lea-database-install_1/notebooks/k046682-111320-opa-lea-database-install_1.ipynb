{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complex Extraction of Law Enforcement Complaints\n",
        "\n",
        "This PDF contains a set of complaint records from a local law enforcement agency. Challenges include its relational data structure, unusual formatting common in the region, and redactions that disrupt automatic parsing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install natural-pdf\n",
        "!pip install natural-pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the PDF file\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "pdf_url = \"https://pub-4e99d31d19cb404d8d4f5f7efa51ef6e.r2.dev/pdfs/k046682-111320-opa-lea-database-install_1/k046682-111320-opa-lea-database-install_1.pdf\"\n",
        "pdf_name = \"k046682-111320-opa-lea-database-install_1.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_name):\n",
        "    print(f\"Downloading {pdf_name}...\")\n",
        "    urllib.request.urlretrieve(pdf_url, pdf_name)\n",
        "    print(f\"Downloaded {pdf_name}\")\n",
        "else:\n",
        "    print(f\"{pdf_name} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complex Extraction of Law Enforcement Complaints\n",
        "\n",
        "This PDF contains a set of complaint records from a local law enforcement agency. Challenges include its relational data structure, unusual formatting common in the region, and redactions that disrupt automatic parsing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf import PDF\n",
        "\n",
        "pdf = PDF(\"k046682-111320-opa-lea-database-install_1.pdf\")\n",
        "pdf.show(cols=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at a single page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page = pdf.pages[0]\n",
        "page.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding exclusions\n",
        "\n",
        "We don't like the top and bottom areas, so we'll exclude them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf.add_exclusion(lambda page: page.find(text='L.E.A. Data Technologies').below(include_source=True))\n",
        "pdf.add_exclusion(lambda page: page.find(text='Complaints By Date').above(include_source=True))\n",
        "\n",
        "page.show(exclusions='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Breaking into sections\n",
        "\n",
        "Even though you might think the colors are the best route to tackle this \u2013 they stand out! \u2013 I think text is usually the best option.\n",
        "\n",
        "We'll tell it to break the pages into sections by the **Recorded On Camera** text. We tell it `include_boundaries='start'`.\n",
        "\n",
        "> Originally I did this with **Location of Occurrence** but apparently it's a *little bit lower* than the recording header and caused some problems later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sections = pdf.get_sections(\n",
        "  'text:contains(Recorded)',\n",
        "  include_boundaries='start'\n",
        ")\n",
        "sections.show(cols=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at one of the sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "section = sections[3]\n",
        "section.show(crop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This extraction is made easier since **they're all generally the same**, they all have the same formatting even if they're missing data.\n",
        "\n",
        "## Extracting the top area\n",
        "\n",
        "Up top we'll focus on grabbing the labels, then going right until we find a piece of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "complainant = (\n",
        "  section\n",
        "  .find(\"text:contains(Complainant)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "print(\"Complainant is\", complainant.extract_text())\n",
        "complainant.show(crop=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that date of birth and some other fields are *missing*. Usually this means we'd have to use `right(100)` or pick some manual pixel value, but it turns out even the missing data includes text elements - they're just empty! That means we can use `until='text'` instead of magic numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dob = (\n",
        "  section\n",
        "  .find(\"text:contains(DOB)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "print(\"DOB is\", dob.extract_text())\n",
        "dob.show(crop=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the above/below pieces it's slightly more problematic. By default when you expand downwards, it doesn't select the *entire* piece of text, it only grabs the ones that intersect with your search area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number = (\n",
        "    section\n",
        "    .find(\"text:contains(Number)\")\n",
        "    .below(until='text', width='element')\n",
        ")\n",
        "print(\"Number is\", number.extract_text())\n",
        "number.show(crop=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to be sure you get the entire thing you need to ask for text that even partially overlaps the area you have selected. This makes the area expand to cover all of the number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number = (\n",
        "    section\n",
        "    .find(\"text:contains(Number)\")\n",
        "    .below(until='text', width='element')\n",
        "    .find('text', overlap='partial')\n",
        ")\n",
        "print(\"Number is\", number.extract_text())\n",
        "number.show(crop=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The elements like \"Date Assigned\" and \"Completed\" are a little more difficult, as you want to be sure you're only grabbing the text *fully and directly underneath* the label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "  section\n",
        "  .find('text:contains(Date Assigned)')\n",
        "  .below(width='element')\n",
        "  .show(crop=100)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do this by grabbing the area below, then asking it to find the first piece of text inside the created box full overlap. By default it only picks text that is *fully inside*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "  section\n",
        "  .find('text:contains(Date Assigned)')\n",
        "  .below(width='element')\n",
        "  .find('text')\n",
        "  .extract_text()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we did `until='text'` it would grab the *first text it touched*, so it would grab the Seargant.\n",
        "\n",
        "With that all in line, when we start to grab them all it looks something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "complainant = (\n",
        "  section\n",
        "  .find(\"text:contains(Complainant)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "dob = (\n",
        "  section\n",
        "  .find(\"text:contains(DOB)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "address = (\n",
        "  section\n",
        "  .find(\"text:contains(Address)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "gender = (\n",
        "  section\n",
        "  .find(\"text:contains(Gender)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "phone = (\n",
        "  section\n",
        "  .find(\"text:contains(H Phone)\")\n",
        "  .right(until='text')\n",
        ")\n",
        "date_assigned = (\n",
        "  section\n",
        "  .find('text:contains(Date Assigned)')\n",
        "  .below(width='element')\n",
        "  .find('text')\n",
        ")\n",
        "completed = (\n",
        "  section\n",
        "  .find('text:contains(Completed)')\n",
        "  .below(width='element')\n",
        "  .find('text')\n",
        ")\n",
        "recorded = (\n",
        "  section\n",
        "  .find('text:contains(Recorded)')\n",
        "  .below(until='text', width='element')\n",
        ")\n",
        "\n",
        "(complainant + dob + address + gender + phone + date_assigned + completed + recorded).show(crop=section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> I'm sorry, I got lazy \u2013 I trust you understand and can fill the rest of them out on your own!\n",
        "\n",
        "## Capturing the complaint table\n",
        "\n",
        "The tables might seem intimidating, but it's really only a question of isolating the area and then using `.extract_table()`.\n",
        "\n",
        "How can we describe the \"Complaint\" area? Well, it's **to the right of a bunch of `Complaint #` text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    section\n",
        "    .find_all('text:contains(Complaint #)')\n",
        "    .right(include_source=True)\n",
        "    .show(crop=section)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could probably grab each of the text elements individually and parse out the columns, but instead we'll use `.merge()` to combine them into one big region, then nudge it up and down a little bit to capture the entire table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    section\n",
        "    .find_all('text:contains(Complaint #)')\n",
        "    .right(include_source=True)\n",
        "    .merge()\n",
        "    .expand(top=5, bottom=7)\n",
        "    .show(crop=section)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's too much work to try to capture the headers programmatically, so we'll just manually type them in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    section\n",
        "    .find_all('text:contains(Complaint #)')\n",
        "    .right(include_source=True)\n",
        "    .merge()\n",
        "    .expand(top=5, bottom=7)\n",
        "    .extract_table()\n",
        "    .to_df(header=['Type of Complaint', 'Description', 'Complaint Disposition'])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unfortunately this doesn't work on all of the tables: some of the ones with redactions trick the columnd detector! So we'll use **Guides** to detect a *specific number of columns* based on the lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf.analyzers.guides import Guides\n",
        "\n",
        "# Find the area\n",
        "table = (\n",
        "    section\n",
        "    .find_all('text:contains(Complaint #)')\n",
        "    .right(include_source=True)\n",
        "    .merge()\n",
        "    .expand(top=5, bottom=7)\n",
        ")\n",
        "\n",
        "# Build vertical guidelines from lines\n",
        "guides = Guides(table)\n",
        "guides.vertical.from_lines(n=4)\n",
        "\n",
        "# Use the guides\n",
        "(\n",
        "  table\n",
        "  .extract_table(verticals=guides.vertical)\n",
        "  .to_df(header=['Type of Complaint', 'Description', 'Complaint Disposition'])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Capturing the officers table\n",
        "\n",
        "We take the same tack for the officers table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_area = (\n",
        "    section\n",
        "    .find_all('text:contains(Officer #)')\n",
        "    .right(include_source=True)\n",
        "    .merge()\n",
        "    .expand(top=5, bottom=7)\n",
        ")\n",
        "\n",
        "guides = Guides(table)\n",
        "guides.vertical.from_lines(n=8)\n",
        "\n",
        "(\n",
        "  table\n",
        "  .extract_table(verticals=guides.vertical)\n",
        "  .to_df(header=['Name', 'ID No.', 'Rank', 'Division', 'Officer Disposition', 'Action Taken', 'Body Cam'])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A nice #todo for me is to integrate this into `.extract_table`. Something like `.extract_table(columns=4)` would look nice, no?\n",
        "\n",
        "## Combining all of the data in one CSV\n",
        "\n",
        "First we can pop through each section and extract the information we're looking for. I added a little expansion for the Date Assigned/Completed pieces as the dates are sometimes a little longer than the header."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for section in sections:\n",
        "    complainant = section.find(\"text:contains(Complainant)\").right(until='text')\n",
        "    dob = section.find(\"text:contains(DOB)\").right(until='text')\n",
        "    address = section.find(\"text:contains(Address)\").right(until='text')\n",
        "    gender = section.find(\"text:contains(Gender)\").right(until='text')\n",
        "    phone = section.find(\"text:contains(H Phone)\").right(until='text')\n",
        "    investigator = (\n",
        "        section\n",
        "        .find(\"text:contains(Investigator)\")\n",
        "        .below(until='text', width='element')\n",
        "        .find('text', overlap='partial')\n",
        "    )\n",
        "    number = (\n",
        "        section\n",
        "        .find(\"text:contains(Number)\")\n",
        "        .below(until='text', width='element')\n",
        "        .find('text', overlap='partial')\n",
        "    )\n",
        "    date_assigned = (\n",
        "      section\n",
        "      .find('text:contains(Date Assigned)')\n",
        "      .below(width='element')\n",
        "      .expand(left=5, right=5)\n",
        "      .find('text')\n",
        "    )\n",
        "    completed = (\n",
        "      section\n",
        "      .find('text:contains(Completed)')\n",
        "      .below(width='element')\n",
        "      .expand(left=5, right=5)\n",
        "      .find('text')\n",
        "    )\n",
        "    recorded = (\n",
        "      section\n",
        "      .find('text:contains(Recorded)')\n",
        "      .below(until='text', width='element')\n",
        "      .expand(left=5, right=5)\n",
        "    )\n",
        "    \n",
        "    row = {}\n",
        "    row['complainant'] = complainant.extract_text()\n",
        "    row['investigator'] = investigator.extract_text()\n",
        "    row['number'] = number.extract_text()\n",
        "    row['dob'] = dob.extract_text()\n",
        "    row['address'] = address.extract_text()\n",
        "    row['gender'] = gender.extract_text()\n",
        "    row['phone'] = phone.extract_text()\n",
        "    row['date_assigned'] = date_assigned.extract_text()\n",
        "    row['completed'] = completed.extract_text()\n",
        "    row['recorded'] = recorded.extract_text()\n",
        "    rows.append(row)\n",
        "\n",
        "print(\"We found\", len(rows), \"rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can push it into pandas without a problem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the tables as combined CSVs\n",
        "\n",
        "Usually when you have a number of similar tables in one PDF, you don't want to make a bunch of different CSV files, you want to **put them all into one CSV**.\n",
        "\n",
        "We'll do that by looping through each section like we did before, but we'll also add a new column to our data: the `number`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "officer_dfs = []\n",
        "for section in sections:\n",
        "    # Not every section has officers, exit\n",
        "    # early if Officer number not mentioned\n",
        "    if 'Officer #' not in section.extract_text():\n",
        "      continue\n",
        "\n",
        "    # Grab the case number\n",
        "    case_number = (\n",
        "        section\n",
        "        .find(\"text:contains(Number)\")\n",
        "        .below(until='text', width='element')\n",
        "        .find('text', overlap='partial')\n",
        "        .extract_text()\n",
        "    )\n",
        "\n",
        "    # Grab the table area\n",
        "    table = (\n",
        "        section\n",
        "        .find_all('text:contains(Officer #)')\n",
        "        .right(include_source=True)\n",
        "        .merge()\n",
        "        .expand(top=3, bottom=6)\n",
        "    )\n",
        "    \n",
        "    # Use the guides to extract the table\n",
        "    guides = Guides(table)\n",
        "    guides.vertical.from_lines(n=8)\n",
        "    columns = ['Name', 'ID No.', 'Rank', 'Division', 'Officer Disposition', 'Action Taken', 'Body Cam']\n",
        "    officer_df = (\n",
        "      table\n",
        "      .extract_table(verticals=guides.vertical)\n",
        "      .to_df(header=columns)\n",
        "    )\n",
        "\n",
        "    # Add to your list\n",
        "    officer_df['case_number'] = case_number\n",
        "    officer_dfs.append(officer_df)\n",
        "\n",
        "# Combine the dataframes\n",
        "print(\"Combining\", len(officer_dfs), \"officer dataframes\")\n",
        "df = pd.concat(officer_dfs, ignore_index=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Repeat the same thing for complaints (just changing `n=8` to `n=4`) and you'll be good to go!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting State Agency Call Center Wait Times from FOIA PDF\n",
        "\n",
        "This PDF contains data on wait times at a state agency call center. The main focus is on the data on the first two pages, which matches other states' submission formats. The later pages provide granular breakdowns over several years. Challenges include it being heavily pixelated, making it hard to read numbers and text, with inconsistent and unreadable charts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install natural-pdf\n",
        "!pip install natural-pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the PDF file\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "pdf_url = \"https://pub-4e99d31d19cb404d8d4f5f7efa51ef6e.r2.dev/pdfs/statecallcenterdata_redacted/statecallcenterdata_redacted.pdf\"\n",
        "pdf_name = \"statecallcenterdata_redacted.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_name):\n",
        "    print(f\"Downloading {pdf_name}...\")\n",
        "    urllib.request.urlretrieve(pdf_url, pdf_name)\n",
        "    print(f\"Downloaded {pdf_name}\")\n",
        "else:\n",
        "    print(f\"{pdf_name} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extracting State Agency Call Center Wait Times from FOIA PDF\n",
        "\n",
        "This PDF contains data on wait times at a state agency call center. The main focus is on the data on the first two pages, which matches other states' submission formats. The later pages provide granular breakdowns over several years. Challenges include it being heavily pixelated, making it hard to read numbers and text, with inconsistent and unreadable charts.\n",
        "\n",
        "The submission said \"the first two pages\" so I'm going with that. The rest of the pages are *insane* and will need a wholly separate writeup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf import PDF\n",
        "\n",
        "pdf = PDF(\"statecallcenterdata_redacted.pdf\")\n",
        "page = pdf.pages[0]\n",
        "page.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pages are images so they don't have text, but we can always double-check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# No results? Needs OCR!\n",
        "print(page.extract_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I love [surya](https://github.com/datalab-to/surya) so I'm going to use it instead of the default of easyocr. Two ways to check the results: look at where it found text and look at what the text is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "page.apply_ocr('surya')\n",
        "page.find_all('text').show(crop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now we'll look at what the text is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(page.extract_text(layout=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get the table area, we get everything from the \"Figure\" header down to \"Please use the comments field\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_area = (\n",
        "    page\n",
        "    .find('text:contains(Figure)')\n",
        "    .below(\n",
        "        until='text:contains(Please use the comments)',\n",
        "        include_endpoint=False\n",
        "    )\n",
        ")\n",
        "table_area.show(crop='wide')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to cut it in on the sides a little bit, and expand it on the bottom. I just pick some manual values because I'm lazy, should probably be a better way to resize things based on selectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_area = (\n",
        "    page\n",
        "    .find('text:contains(Figure)')\n",
        "    .below(\n",
        "        until='text:contains(Please use the comments)',\n",
        "        include_endpoint=False\n",
        "    )\n",
        "    .expand(\n",
        "        right=-(page.width * 0.58),\n",
        "        left=-30,\n",
        "        bottom=3\n",
        "    )\n",
        ")\n",
        "table_area.show(crop='wide')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can see all the text in our area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_area.find_all('text').show(crop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For some reason we can't just use `.extract_table('stream')` on this, even though there are some nice gaps between each column. Oh well!\n",
        "\n",
        "Instead we'll throw three vertical dividers in and then shuffle then around until they don't intersect any of the text. The horizontal borders are easier because they're just lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf.analyzers.guides import Guides\n",
        "\n",
        "guide = Guides(table_area)\n",
        "guide.vertical.divide(3)\n",
        "guide.vertical.snap_to_whitespace(detection_method='text')\n",
        "guide.horizontal.from_lines()\n",
        "guide.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now we can grab the table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = (\n",
        "  guide\n",
        "  .extract_table()\n",
        "  .to_df(\n",
        "    header=['value', 'amount', 'comments']\n",
        "  )\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next page is....... too hard for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf.pages[1].show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Arabic Election Results Table Extraction from Mednine PDF\n",
        "\n",
        "This PDF has a data table showing election results from the Tunisian region of Mednine. Challenges include spanning header cells and rotated headers. It has Arabic script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install natural-pdf\n",
        "!pip install natural-pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the PDF file\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "pdf_url = \"https://pub-4e99d31d19cb404d8d4f5f7efa51ef6e.r2.dev/pdfs/mednine/mednine.pdf\"\n",
        "pdf_name = \"mednine.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_name):\n",
        "    print(f\"Downloading {pdf_name}...\")\n",
        "    urllib.request.urlretrieve(pdf_url, pdf_name)\n",
        "    print(f\"Downloaded {pdf_name}\")\n",
        "else:\n",
        "    print(f\"{pdf_name} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Arabic Election Results Table Extraction from Mednine PDF\n",
        "\n",
        "This PDF has a data table showing election results from the Tunisian region of Mednine. Challenges include spanning header cells and rotated headers. It has Arabic script.\n",
        "\n",
        "Updated for testing caching system with cascading dependencies!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf import PDF\n",
        "\n",
        "pdf = PDF(\"mednine.pdf\")\n",
        "pdf.show(cols=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I spent far too long making sure Natural PDF supports right-to-left scripts like Arabic. While I can't read them to confirm, I'm vaguely confident that the text we're pulling from the PDF is accurate.\n",
        "\n",
        "/// tab | Multi-page flows\n",
        "## Building a flow\n",
        "\n",
        "Since this PDF is all one big long table with not much else in the way, we can most likely just stack all of the pages on top of each other with a Flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from natural_pdf.flows import Flow\n",
        "\n",
        "flow = Flow(pdf.pages, arrangement='vertical')\n",
        "flow.show(width=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Flows are ways of connecting separate pages or regions vertically or horizontally.\n",
        "\n",
        "## Extracting the table\n",
        "\n",
        "Since we're using a flow we can just rest easy on `.extract_table()`, which automatically combines the tables across the entire flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = flow.extract_table().to_df(header=None)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "///\n",
        "\n",
        "/// tab | Manually combining dataframes\n",
        "If you'd rather not use a Flow, an alternative is going through each page. Instead of a `for` loop I like to use `.apply`, as it keeps things a bit shorter. You could also use a list comprehension!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataframes = pdf.pages.apply(\n",
        "    lambda page: page.extract_table().to_df(header=None)\n",
        ")\n",
        "print(\"Found\", len(dataframes), \"tables\")\n",
        "\n",
        "# Combine\n",
        "df = pd.concat(dataframes, ignore_index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "///\n",
        "\n",
        "I'm a big fan of taking as much information as possible, then cleaning it up later. We *could* spend time wrangling the column headers on the first page, spacing out grids, etc etc etc, but instead *let's just grab the whole thing and sort it out later*.\n",
        "\n",
        "## Cleaning up the data\n",
        "\n",
        "Now it just becomes an exercise in data cleanup! This is something AI coding tools are excellent at, so feel free to lean hard on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use row 2 as header\n",
        "df.columns = df.iloc[3].fillna(df.iloc[2]).str.replace(\"\\n\", \" \")\n",
        "\n",
        "# Drop the first 3 rows\n",
        "df = df.iloc[4:].reset_index(drop=True)\n",
        "\n",
        "# Remove spaces from numbers and convert to int\n",
        "numeric_cols = df.columns[0:4]\n",
        "df[numeric_cols] = df[numeric_cols].replace(r\"\\s+\", \"\", regex=True).astype(int)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
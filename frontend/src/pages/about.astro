---
import '../styles/global.css';
import Header from '../components/Header.astro';
import Footer from '../components/Footer.astro';
const BASE_URL = import.meta.env.BASE_URL;

---

<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>About | bad pdfs</title>
    <meta name="description" content="Learn about bad pdfs - a collection of real-world PDF extraction examples using natural-pdf" />
  </head>
  <body>
    <Header currentPage="about" />
    
    <main class="about-page">
      <div class="container">
        <div class="hero-section">
          <h1>about bad pdfs</h1>
        </div>
        
        <div class="content prose">
          <section>
            <p>
              bad pdfs is a collection of real-world PDF files that demonstrate the challenges 
              of PDF data extraction. Each example shows how to extract data using 
              <a href="https://jsoma.github.io/natural-pdf/" target="_blank" rel="noopener noreferrer">Natural PDF</a>, 
              with complete, working code examples.
            </p>
            <p>
              The gallery started as a way to test natural-pdf on difficult PDFs, but it turns out 
              researchers and journalists deal with these problematic files every day. So we've collected 
              them here to help everyone.
            </p>
          </section>

          <section>
            <h2>Why "bad" PDFs?</h2>
            <p>
              PDFs were designed to display consistently across devices, not to make data extraction easy. 
              Here are the common challenges you'll find in this gallery:
            </p>
            <ul>
              <li>Complex layouts with multiple columns</li>
              <li>Tables without proper structure</li>
              <li>Scanned images requiring OCR</li>
              <li>Forms with inconsistent formatting</li>
              <li>Mixed content types on single pages</li>
            </ul>
            <p>
              We show you how to solve each and every one of these issues with <a href="https://jsoma.github.io/natural-pdf/">Natural PDF</a>.
            </p>
          </section>

          <section>
            <h2>How to Use This Gallery</h2>
            <p>
              <strong><a href={BASE_URL}>Browse Examples</a></strong><br>
              Find PDFs similar to the ones you're working with. Each example includes the original PDF 
              and extraction approaches.
            </p>
            <p>
              <strong>View Extraction Code</strong><br>
              Every example shows complete Python code with the output it produces. The code is tested 
              and ready to use.
            </p>
            <p>
              <strong><a href="${BASE_URL}methods">Search by Method</a></strong><br>
              Use the search to find examples of specific natural-pdf methods like <code><a href="${BASE_URL}methods/extract_table">extract_table()</a></code> 
              or <code><a href="${BASE_URL}methods/apply_ocr">apply_ocr()</a></code>.
            </p>
            <p>
              <strong>Export to Colab</strong><br>
              Run examples directly in Google Colab to experiment with the code on your own PDFs.
            </p>
          </section>

          <section>
            <h2>Contributing</h2>
            <p>
              Have a challenging PDF that others could learn from? We're always looking for new examples, 
              especially from real-world use cases. <a href="https://tally.so/forms/n0lvry">Submit your own bad PDF here</a>.
            </p>
          </section>

          <section>
            <h2>About natural-pdf</h2>
            <p>
              <a href="https://jsoma.github.io/natural-pdf/" target="_blank" rel="noopener noreferrer">natural-pdf</a> 
              is a Python library designed to make PDF extraction more intuitive. It combines traditional 
              extraction methods with modern capabilities like:
            </p>
            <ul>
              <li>Text and table extraction</li>
              <li>Spatial navigation (find content relative to other elements)</li>
              <li>OCR for scanned documents</li>
              <li>AI-powered extraction for complex layouts</li>
              <li>Multi-column layout handling</li>
            </ul>
          </section>

          <section>
            <h2>Why not <a href="https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence">Azure AI Document Intelligence</a> or <a href="https://github.com/datalab-to/marker">Marker</a> or <a href="https://docling-project.github.io/docling/">Docling</a> or whatever else?</h2>
            <p>These libraries are designed for big workflows with 99% accuracy across zillions of kinds of documents.</p>
            <p>In the world of <em>data journalism</em>, though, you usually have one specific format of PDF, and 10,000 versions of it. You also are really aiming for 100% accuracy, so general-purpose solutions don't work as well.

          </section>

          <section class="credits">
            <h2>Credits</h2>
            <p>
              bad pdfs is created and maintained by <a href="https://github.com/jsoma" target="_blank" rel="noopener noreferrer">Jonathan Soma</a>, 
              who teaches data journalism at Columbia University and is the author of natural-pdf. 
            </p>
            <p>
              The project is open source and available on 
              <a href="https://github.com/jsoma/badpdfs-analysis" target="_blank" rel="noopener noreferrer">GitHub</a>.
            </p>
          </section>
        </div>
      </div>
    </main>
    
    <Footer />
  </body>
</html>

<style>
  .about-page {
    min-height: calc(100vh - 80px);
    padding: 3rem 0;
  }

  .container {
    max-width: 800px;
    margin: 0 auto;
    padding: 0 2rem;
  }

  .hero-section {
    text-align: center;
    margin-bottom: 4rem;
  }

  .hero-section h1 {
    font-size: 3rem;
    font-weight: 700;
    margin: 0 0 1rem 0;
    background: linear-gradient(135deg, var(--color-gradient-start) 0%, var(--color-gradient-end) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
  }

  .lead {
    font-size: 1.25rem;
    color: var(--color-text-muted);
    margin: 0;
  }

  .content {
    max-width: 65ch;
    margin: 0 auto;
  }

  /* Let prose class handle most typography */
  .prose {
    color: var(--color-text);
  }

  .prose h2 {
    font-size: 1.75rem;
    font-weight: 700;
    color: var(--color-text);
    margin: 2.5rem 0 1rem 0;
  }

  .prose h3 {
    font-size: 1.25rem;
    font-weight: 600;
    color: var(--color-text);
    margin: 2rem 0 0.5rem 0;
  }

  .prose p {
    margin-bottom: 1.25rem;
  }

  .prose strong {
    color: #111827;
    font-weight: 600;
  }

  .prose ul {
    list-style: disc;
    padding-left: 1.5rem;
    margin-bottom: 1.25rem;
  }

  .prose li {
    margin-bottom: 0.5rem;
  }

  .prose a {
    color: var(--color-primary);
    text-decoration: none;
    transition: color 0.2s ease;
  }

  .prose a:hover {
    color: var(--color-secondary);
    text-decoration: underline;
  }

  .prose code {
    background: var(--color-surface);
    padding: 0.125rem 0.375rem;
    border-radius: 0.25rem;
    font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
    font-size: 0.875em;
    color: var(--color-primary);
  }

  .credits {
    margin-top: 4rem;
    padding-top: 2rem;
    border-top: 1px solid #e5e7eb;
  }

  @media (max-width: 768px) {
    .container {
      padding: 0 1rem;
    }

    .hero-section h1 {
      font-size: 2rem;
    }

    .steps {
      grid-template-columns: 1fr;
      gap: 1rem;
    }
  }

</style>